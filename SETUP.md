# Bleak Monorepo Setup Guide

## âœ… Completed Setup

Your project has been successfully restructured into a monorepo with both frontend and backend components.

## ğŸ—ï¸ Current Structure

```
bleak/
â”œâ”€â”€ package.json              # Root package.json with monorepo scripts
â”œâ”€â”€ package-lock.json         # Root dependencies (concurrently)
â”œâ”€â”€ node_modules/            # Root dependencies
â”œâ”€â”€ .gitignore               # Updated for both frontend and backend
â”œâ”€â”€ README.md                # Updated monorepo documentation
â”œâ”€â”€ SETUP.md                 # This file
â”œâ”€â”€ frontend/                # React + Vite frontend
â”‚   â”œâ”€â”€ src/                # All your existing React code
â”‚   â”œâ”€â”€ package.json        # Frontend dependencies
â”‚   â”œâ”€â”€ vite.config.ts      # Vite configuration
â”‚   â”œâ”€â”€ node_modules/       # Frontend dependencies
â”‚   â””â”€â”€ ...                 # All other frontend files
â””â”€â”€ backend/                 # Python FastAPI backend
    â”œâ”€â”€ src/backend/        # Backend source code
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ main.py         # FastAPI app with CORS
    â”‚   â””â”€â”€ graph.py        # LangGraph implementation
    â”œâ”€â”€ pyproject.toml      # Python dependencies
    â”œâ”€â”€ uv.lock            # Dependency lock file
    â”œâ”€â”€ .venv/             # Python virtual environment
    â””â”€â”€ README.md          # Backend documentation
```

## ğŸš€ Quick Start Commands

### Install All Dependencies

```bash
npm run install:all
```

### Development Mode (Both services)

```bash
npm run dev
```

This starts both frontend (http://localhost:5173) and backend (http://localhost:8000)

### Individual Services

#### Frontend Only

```bash
npm run dev:frontend
# or
cd frontend && npm run dev
```

#### Backend Only

```bash
npm run dev:backend
# or
cd backend && uv run uvicorn backend.main:app --host 0.0.0.0 --port 8000 --reload
```

## ğŸ”— API Integration

The backend provides:

- **Health Check**: `GET http://localhost:8000/health`
- **Chat Endpoint**: `POST http://localhost:8000/chat`
  - Request: `{"message": "Hello", "conversation_id": "optional"}`
  - Response: `{"response": "AI response", "conversation_id": "id"}`
- **API Docs**: `http://localhost:8000/docs`

The frontend is configured to make requests to `http://localhost:8000`

## ğŸ› ï¸ Backend Features

- âœ… FastAPI with async support
- âœ… CORS configured for frontend
- âœ… LangGraph integration for conversation flows
- âœ… Pydantic models for request/response validation
- âœ… Health check endpoint
- âœ… Comprehensive error handling
- âœ… Logging configuration

## ğŸ”§ Next Steps

1. **Add your LangGraph logic** in `backend/src/backend/graph.py`
2. **Configure environment variables** (OPENAI_API_KEY, etc.)
3. **Update frontend API calls** to use the new backend
4. **Customize the conversation flow** in the graph
5. **Add authentication** if needed
6. **Deploy** using your preferred platform

## ğŸ“š Available Scripts

From the root directory:

- `npm run dev` - Start both frontend and backend
- `npm run dev:frontend` - Start only frontend
- `npm run dev:backend` - Start only backend
- `npm run build` - Build both projects
- `npm run install:all` - Install all dependencies
- `npm run start` - Start both in production mode

## ğŸ§ª Testing the Setup

1. Start both services: `npm run dev`
2. Check frontend: http://localhost:5173
3. Check backend health: http://localhost:8000/health
4. Check API docs: http://localhost:8000/docs
5. Test chat endpoint with curl:
   ```bash
   curl -X POST "http://localhost:8000/chat" \
     -H "Content-Type: application/json" \
     -d '{"message": "Hello, world!"}'
   ```

## ğŸ¯ Your Code Integration

To integrate your existing LangGraph code:

1. Replace the placeholder logic in `backend/src/backend/graph.py`
2. Update the `process_message` function with your AI logic
3. Add any additional dependencies to `backend/pyproject.toml`
4. Run `uv sync` to install new dependencies

The current setup provides a working foundation that you can build upon!
